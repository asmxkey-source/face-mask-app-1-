import streamlit as st
import cv2
import tempfile
import google.generativeai as genai
import numpy as np
import os
from PIL import Image

st.set_page_config(page_title="AI ì–¼êµ´ ë¹„ì‹ë³„í™”", layout="centered")
st.title("ğŸ¥ AI ì˜ìƒ ì–¼êµ´ ë§ˆìŠ¤í‚¹")

# 1. API í‚¤ ì„¤ì •
api_key = st.sidebar.text_input("Gemini API Key", type="password")

if api_key:
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel('gemini-1.5-flash') # ì˜ìƒ ì´í•´ì— ìµœì í™”ëœ ëª¨ë¸

    uploaded_file = st.file_uploader("ì˜ìƒì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=['mp4', 'mov', 'avi'])

    if uploaded_file:
        # íŒŒì¼ ì €ì¥
        tfile = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
        tfile.write(uploaded_file.read())
        video_path = tfile.name

        st.video(video_path)

        if st.button("ì–¼êµ´ ë§ˆìŠ¤í‚¹ ì‹œì‘"):
            with st.spinner("AIê°€ ì˜ìƒì„ ë¶„ì„í•˜ê³  ì–¼êµ´ì„ ê°€ë¦¬ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                try:
                    # 2. Geminiì—ê²Œ ì˜ìƒ ì—…ë¡œë“œ ë° ì–¼êµ´ ì¢Œí‘œ ìš”ì²­
                    st.info("AIì—ê²Œ ì˜ìƒ ë¶„ì„ì„ ìš”ì²­í•˜ëŠ” ì¤‘...")
                    video_file = genai.upload_file(path=video_path)
                    
                    # ì–¼êµ´ ì¢Œí‘œ ì¶”ì¶œ í”„ë¡¬í”„íŠ¸
                    prompt = "Find all human faces in this video and provide their coordinates as [ymin, xmin, ymax, xmax] in JSON format for each frame."
                    response = model.generate_content([video_file, prompt])
                    
                    # 3. OpenCV ì˜ìƒ ì²˜ë¦¬
                    cap = cv2.VideoCapture(video_path)
                    width = int(cap.get(cv2.è·æ¥­_FRAME_WIDTH))
                    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                    fps = cap.get(cv2.CAP_PROP_FPS)
                    
                    # ê²°ê³¼ ì˜ìƒ ì €ì¥ ì„¤ì •
                    output_path = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4').name
                    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
                    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

                    while cap.isOpened():
                        ret, frame = cap.read()
                        if not ret: break

                        # [í•µì‹¬ ë¡œì§] Geminiê°€ ì¤€ ì¢Œí‘œë¥¼ í”„ë ˆì„ì— ì ìš© (ê°„ëµí™”ëœ ì˜ˆì‹œ)
                        # ì‹¤ì œ êµ¬í˜„ì‹œ responseì—ì„œ íŒŒì‹±í•œ ì¢Œí‘œë¡œ cv2.GaussianBlur ì ìš©
                        # ìš°ì„ ì€ ì¤‘ì•™ë¶€ ìƒ˜í”Œ ë¸”ëŸ¬ë¡œ ì‘ë™ í™•ì¸
                        h, w, _ = frame.shape
                        face_region = frame[h//4:3*h//4, w//4:3*w//4]
                        blurred_face = cv2.GaussianBlur(face_region, (99, 99), 30)
                        frame[h//4:3*h//4, w//4:3*w//4] = blurred_face
                        
                        out.write(frame)

                    cap.release()
                    out.release()

                    st.success("ì²˜ë¦¬ ì™„ë£Œ!")
                    st.video(output_path)
                    
                    with open(output_path, "rb") as f:
                        st.download_button("ê²°ê³¼ë¬¼ ë‹¤ìš´ë¡œë“œ", f, "masked_video.mp4")

                except Exception as e:
                    st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
else:
    st.info("ë¨¼ì € ì‚¬ì´ë“œë°”ì— API í‚¤ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
